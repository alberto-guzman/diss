# Paper 2: College access during COVID-19: evaluating the use of an AI-chatbot for college application and enrollment

## Introduction

In spring 2020, colleges and universities across the US began to shut down due to the ongoing COVID-19 outbreak. Due to the pandemic, the high school graduating class of 2020 faced increased uncertainty in what ordinarily would be their timely transition to college. At the time, the effect of the pandemic on college-going was uncertain. On the one hand, the COVID-19 crisis hampered business-as-usual operating procedures for colleges. Because of this, students -- particularly those planning to attend a residential college -- may have been more likely to delay college entry. On the other hand, higher education is a counter-cyclical industry such that college enrollment rates tend to be higher during economic downturns. For recent high school graduates, in particular, the impact of the pandemic on service and retail, among other sectors, may severely limit job opportunities. This, in turn, may make higher education an attractive option for young adults who might otherwise enter the labor market after high school.

In response to the uncertainty of the impact of the pandemic on college enrollment, the Common Application (Common App), in partnership with Mainstay and the College Advising Corps (CAC), acted quickly to provide students with proactive outreach and guidance on college-going tasks via an innovative large-scale chatbot campaign. This outreach specifically targeted US high school students who were the first in their families to go to college and had low family income, most of whom were students of color (83%). Due to a variety of systemic and structural barriers, some of these students likely faced limited access to quality health care, living and work conditions during the pandemic (CITE). Therefore, these students would likely benefit from additional support during their precarious college transition.

Over 38 weeks, a Mainstay artificially intelligent (AI) chatbot named *Oli* sent scripted messages to students on various topics related to the college search, application, and matriculation processes. To better target the information, Oli solicited information directly from students about the types of resources they needed and pressing questions they had. Student questions that Oli could not answer were forwarded to college advisers, who would follow up directly with individual students. The outreach campaign was ambitious in scope, reaching nearly 174,000 students across the US.

The present study is in line with recent work focused on levering behavioral economics insights with AI chatbots to alleviate the complexities in a student's transition from high school to college (CITE). Those studies found somewhat positive effects of using chatbots deployed within a specific university context on pre-matriculation tasks and seamless college enrollment (CITE). However, there is no evidence of the scalability of these kinds of interventions when a chatbot is and a huge numer of students

used 1) outside a university and 2) targeting a large population of students transitioning to college.

Therefore, in my first dissertation study, I evaluate the effectiveness of the Common App AI chatbot outreach on student college-going outcomes. Specifically, I focus on whether the outreach campaign resulted in more students applying to and enrolling in college. In addition, I explore variation in outreach impact on college enrollment by students' application behavior, racial/ethnic subgroups, and level of engagement with the chatbot.

In the following sections, I will review the relevant literature for this study, followed by a description of the data and the analytic strategy I employ. Finally, I present the preliminary results of the evaluation.

## Literature Review

For this study, I draw on prior college access and success research, particularly on literature addressing the challenges for low-income, first-generation students via behavioral nudge interventions. Specifically, I focus on recent evaluations of AI chatbots in the college access space.

Before I review the literature, I want to expand on how I conceptualize first-generation, low-income students. I take an anti-deficit approach to my grounding of first-generation, low-income students, many of whom are students of color (CITE). Anti-deficit approaches explore how marginalized students persist in the face of social and structural barriers (CITE, Harper). The goal is to reframe students' experiences from struggling to ones of resiliency. Since most deficit approaches focus on what students lack, anti-deficit strategies focus on what students bring that leads to their resiliency and persistence.

> Harper, S. R. (2010). An anti-deficit achievement framework for research on students of color in STEM. New Directions for Institutional Research, 2010(148), 63--74. https://doi.org/10.1002/ir.362

### College Attainment among Low-Income and First-Generation Students

Despite increasing access to higher education in recent decades, there are still disparities in college attainment by socioeconomic status and parental education (CITE). Students whose parents received a college degree enroll in college at higher rates than those parents who did not complete high school (CITE). Additionally, students from wealthier backgrounds are more likely to enroll and complete postsecondary education than students from less-resourced families (CITE). For example, around 13% of students from the lowest income brackets earn a bachelor's degree by age 24, compared to 64% of students from the highest income brackets (CITE). Disparities in college access and completion -- along with social and structural barriers -- exacerbate the growing income inequality in the US.

> Castleman, B. L. & Page, L. C. (2015). Summer nudging: Can personalized text messages and peer mentor outreach increase college going among low-income high school graduates? Journal of Economic Behavior & Organization, 115, 144--160. https://doi.org/10.1016/j.jebo.2014.12.008

A proposed reason for the widening gaps in college attainment for first-generation and low-income students has been the lack of access to social capital in navigatins the higher education system (Perna, 2006). Social capital is broadly defined as the access to and resrouces within a social nerworks (Lin, 1991). By definition, first-generation and low-income students likely lack familial support witht he required knowledge of navigating the college-going process. This lack of access to social capital to face a "cultural clash" when navigating into and through college as they must learn the complex process of navigating the college access pipeline from individuals outside their families or imediate social groups (CITE). However, most of the existing literature fails to focus on what these students *gain* from strong familial supports, particularly for students of color. For many first-generation students familial support provide a major source of college aspirations (CITE). Furthermore, first-genration and low-income students gain emotionla support for their families which ease their transition into college, and many report this emotional suport being a major reason for sucessing in college (CITE). This precarious journey was made more precarious by students navigating college going in the backdrop of a global pandemic.

### College access during covid

The COVID-19 outbreak increased uncertainty for the high school gradution class of 2020 in what ordinarily would be their timely transition to college. In the early stages of the pandemic one in six recent high school graduates reported rethinking their decision to enroll in college, with nearly two-thirds expressing concerna bout attending their first choice college. The most cited reeson for not attending their first choice was concern over the ability for their families to afford college.

Now, nearly three years into the pandemic, we have some evidence as to the detrimental effects of the pandemic on college-going and college life. Enrollment for first-time undergraduates in fall 2020 fell to unprecedented levels, dropping nearly 10 percentage points compared to fall 2019, with higher rates for students from low-income high schools (CITE), as well as students fro high minority schools student from low0minority high well were more liley to enroll imddeaitly that those from high schools iwth more diverse students 64% vs 52%.

The added effect of a helath crisis plus a pandemic changed the firly constant countercyclian cycle of college enrollment increasing during economic downturns. Student may turn to afforable opoitons during economic downturns. Therfoer its supirisng to see a turn away from these colleges

A recent report from the College Board provided some more details on the detrimental effects of the pandemic on college going. Draving on data of nearly 10 million students if the US the College board provides high level descrpitives and regression adjusted models identifying the protiion of fall 2020 enrollment rates that are sttributal to covdid-19. They find that the largest shift in student enrollment occured within community colleges, where enrollment rates declined by nearly 12% because of the pandemic, while enrollment was smaller at privare four and public four years (4.5% vs 2.8 , respecly.) Concernign, is that enrollment rates were fell disporotions for community college students in first-geneation, low-income studnets.

Students were facing a multitude of stressors on top of accessing college. Could of been additional responsivbility, feelings of isolation, etc.

Students were not pshychology ready to go to college, tremendous uncertainty.

FG/mino students faced tremendous setback during covid. They may of come from household were they were worried about their parents and family, unlike working class individuals. They also faced dual pandemics spurred on by george floyd. Oli may of helped the feeling of isolation, but it may of been too little to help students struggling with so many other things goign on that college may of not been at the forefront survival was...

In addition additonal barriers were exhacebated for low-income cummunity of coleor. For wexmaple for these gropus access to mentlah heatl services was severely limited. As well as access to qulaity helathcare

The pandemic was characterized by school closures and a pivot to distance/virtual learning. At the time, the pandemic's effect on college-going was uncertain. On the one hand, the COVID-19 crisis hampered business-as-usual operating procedures for colleges and universities. Because of this, students -- particularly those planning to attend a residential college -- may have been more likely to delay college entry. On the other hand, higher education is a counter-cyclical industry such that college enrollment rates tend to be higher during economic downturns. For recent high school graduates, in particular, the impact of the pandemic on service and retail, among other sectors, may severely limit job opportunities. This, in turn, may make higher education an attractive option for young adults who might otherwise enter the labor market after high school.

The pandemics effects disproporitionatley affected marginalized students. Students from higher incomes were far more liley to enroll in college imediately after high school gradution (65%) compared to students from low-income high schools (49%).

Many students did not take a gap year, if anything they was s mall decline in gap year take up comapred to previous years, 2.2 to 2.0 percentage points

. One in six high school seniors who expected to enroll in a four-year instiions before the outbreak reported switching taking a different posecondary plan, for nearly a quarter of respondents believed their first choice was no longer afordable based on considered an option closer to home.

Once students arrived at college in fall 2020, the effects of the ongoing pandemic were exacerbated, with increased rates of anxiety and depression among undergraduate students. First-generation and low-income students faced additional challenges during the pandemic, such as increased financial hardships. First-generation students were nearly twice as likely to be

concerned about paying for education expenses in fall 2020 than non-first-generation students. They also were less likely to report living in a safe environment and more likely to experience food and housing insecurity.3

The outreach undertaken by Common App and its partners was swift and cast a wide net in hopes of helping students through the typically challenging transition to college during this unusually challenging time. We applaud Common App and its partners for undertaking this outreach.

LeBouef, S. & Dworkin, J. (2021). First-Generation College Students and Family Support: A Critical Review of Empirical Research Literature. Education Sciences, 11(6), 294. https://doi.org/10.3390/educsci11060294

### College going process

Considerable research attention has been paid to the roadblocks that first-generation low-income students often face in accessing postsecondary education (CITE). Student begin with navigating the college application process where by, students must complete complex administrative steps such as succesfully submitting college applicaitons, applying for various forms of financial aid, and weightin competing admissions offers. After a students accepts an offer students must then navigate the equally complex college enrollment process, where by they must complete a series of pre-matriculation task such as submitting high school transcripts to their college. For fist-generation and low-income students their is an added complexitie of having to complete these task with little to no prior knowledge of navigating this process, compared to continuing education students. If a student falters at any of these steps students may ultimately fail to matriculate into college.

It is important to note that first-generation and low-income students are also more likely to come from families of lower socioeconomic status and to be an ethnic or racial minority. The roadblocks to college access are compounded for students of color that must also reckod with due to an array of social and systemic barriers that have traditinally left these students with less access to high quality primary and secondary education, including less access to college prepatory courses (CITE)

### Summer Melt

Without the access to supports during studetns college going process many may ultimately fail to matriculate through a phenomena theremed "summer melt." Summer melt describes the process by which college-intentind high school graduates fail to enroll in the fall semester due to challenged in navigating the array of pre-matriculating tasks (CITE). Castleman & Page have found that summer rate affect an estimated 10 to 20 percent of college intentind high school students, with higher rates for low-income, first-generation students. Most concering, is that summer melt disproportionately affects students who are low-income and first generations, and students of color and may not have access to the informations hleping navigate these complex adminsitrative tasks.

There are many mechanims that may explain why students experience summer melt. The predominant one is student failing to enroll because of minimal guidance in navigating pre-matriculation task, which could include missing key deadlines for financial aid, or failing to submit transcripts or various documentation. Therefore, an array of researchers have dedicated work to examing ways to remedy summer melt by supporitng students who have minimal college guidance in the key steps and deadlines to enroll in college by providing high quality college advising via different avenus.

### Interventions Remedying Summer Melt

One favored approach to remediying the lack of information students face on their road to college access is access to high quality college advising that can help students transition to college. However for low-income students, students of color, and first-generation students -- due to systemic barriers such as redlining (CITE) -- tend to reside in high schools with little to no access to high quality college advising, and when they do advisers have large caseloads (CITE).

The liteature points to the positve effects of college advisos is associated with enrolling in college at higher rates, and postively associated with persistance trhough college. For example Castleman et al., 2012 randomized students in secon Rhode Island high schools to received high quality one on one college counseling. This "high touch" intervention resultted in a increate in students imediate college enrollment by 14 percentage points. Although this intervention occured in a relatively diverse schools, all school sin the sample where choice schools and therefore the results may not generalize to public schools. However, in 20 CAstlman and Page look at similar efforts with a nationally representative sample of boston public school students.

Lack of access to these support may make students put off important college going task or simply be unaware of deadlines, such as completing finacil aid applicaitons to scucess matriculating into college.

Therefore appraoches that bring college advising directly to students who need it most is crucial. Once such low-cost way that has ben prosposed has been low-cost nudge interventions based on beahvioral economisc (CITE). These intervention distill complex information and deadlines into short concise megaing delived to students via a mode of communication studenets are well away of, text messages. In the domain of college access these studies have primarily focused on helping student vaigtate well-defined but complex task such as compleitng finalcial aid applicaiton, submitting trasncipt, accepting loand and paying tuition.

A number of randomized trial in higher educaiton have evaluated the use of thsese sort of nudge interventions to remedy summer melt. Such as givign students access to a highly trained college counselor (CITE). these effors improved student on-tine colleg enrollment.Canstleman and Page have undetakern several large randomized controll studies to support college-intending high school student with college going tak and comple the FAFSA

TALK about study

Castleman & Page, 2015, 2017; Castleman, Page & Schooley, 2014) and to file or refile the FAFSA (Castleman & Page, 2016; Page, Castleman & Meyer, 2019).

Hoewever, the research is mixed in the effectivenss of these interventions when they are scaled up. Oreopeoplou et al. find no effect of text message outreach on college studenet grades or completion or when the entity dong the messaging is unfamiliar to the student. for exmaple they find that FAFSA submision are null.

Although these intervention find positive effect, the scalability and const prove to be a problem. On average these cousenlor and text based interventions costt... In additional one would need a large amount of counselors to provide personliaze 1:1 support.

### AI Chat-bots in college access

A recent push in th enudge literature has been to levelrea artifial intelligence (AI) to provide personalized support to students navigating college applicaiton and enrollment. These AI bots have primarily been teasting using AI chatbots. These chatbots are no different that the boths that many business such as cell phone companies use to provide supoprt to customers tryign to access their account, or buy a cellphone. These AI bots are trained by human superision to provide suport to students. Overtime the AI "learns" how to handle increasinlgy complex questions such as XXX. Once sucessfull trained and deployed to student the AI can help student andwer quesitons around important deadlines to when they should submit their transcripts. These chatbots are able to provide sutdent real-time responses based on prior students bot interactions and information provided by the institions.

A series of recent studies conducted by Page, Gelhbach and collegeues have exmployed AI chatbots to help student enroll and navigate college (CITE). In the first studdy Page and Gelbach (2017) used in AI chatbot named "Pounce" located in Georgia Stata Universtiy (GSU) helped freshmanstudents who were accpeted to join GSU in fall 2017 with on time matricutiona and pre-matriculation task at GSU. The use of the chatbot lead to a 3.3 percentage point increase in timenly enrollment at GSU as well as well as hlped students with pre-matriculation class like signing up for orientation. Note this study was situatiod at the instituion where students were planning to enroll. This centralized nature of the intervention is important even among regular nudge interventions. This on is on adminsitrative processes

Nushatayeva and collegesfurther exten the work of Page and gelbach 2017 by testing if AI chatbots are parttucala hlepuf for cetain student subgroup (e.g. ). This study took place at EAst Carolina Univesicy ECU with an AI chatbot names PeeDee. The authors found no overall effect of the chatbot on college enrollment, but did find an effect on loan acceptance rates. The authors point to realtive advanataged student body and ECU to explain their null effect on college enrollmentcompared to overall positive effect on college enrollment found in the GSU study. However, authors did find a postive treatment effects for first-generation students. PeeDee lead to an increace of enrolling at ECU by 3 percentage points for first-generation students, and an increase of completing pre-matriculation task such as accpeintg a loan (8 percentage point incres), and registerign fro class (3 percentage point increase).

Finally in a follow up study by Page and colleges (20202) shifted the focus of the study from helping students enroll at GSU to helpoing students navigate the administrative process after student arrive at GSU. This study specifically, focused on acadmeic support, social and carrer support and administrative processes. This study was employed as a randomized control trisl Through a RCT Page and colelges foudn taht outreach was most effective when the chatbot was focused on adminsitrative process, particualry those that were time sensityve. However, when oureach that focused on suplmente academic, social and carrerl-related suport, such as meeting with an advisor was not found to be effective. The authors conclude that the AI-bot outreach was most effective and changing student bahvior when the bot was focused on discrete, well-defined administion tasks in which a lack of action lead to high consequences, such as resolving registration holds.

Taken together these studies iluminate that AI bots can be an effective tool for helping students transtion into and trhough college, specifically when dealing with adinistratie tasks. However, chat-bot based nudges are not uniformaly effective across various context. These interventions were most effective when providing support to first-generaiton students. An important aspect of these studies to highligh is that these chatbots were housed within a receiving insittions like GSU *not* at a wider level. Little is know about the scalability of these efforts outside universities and at system or national levels.

Page, L. C. & Gehlbach, H. (2017). How an Artificially Intelligent Virtual Assistant Helps Students Navigate the Road to College. AERA Open, 3(4), 2332858417749220. https://doi.org/10.1177/2332858417749220

Page, L., Lee, J. & Gehlbach, H. (2020). Conditions under which college students can be responsive to nudging. EdWorkingPaper.

## Methods

It is important to note that the outreach team did not randomly assign the outreach for this campaign. Randomly assigning the outreach would ensure that students who received the outreach and those who did not would be balanced on both observable *and* unobservable characteristics. Given the lack of randomization, a simple comparison of outcomes between students who received the outreach and those who did not may -- incorrectly -- conclude that the outreach affected the outcome. To guard against this to the fullest extent possible, we matched students in the outreach group to demographically similar students in the same high school who were not treated. These matched students are then observationally similar to students in the outreach group and, therefore, a reasonable comparison group. Analytically, we do this matching via a procedure termed propensity score matching.

### Matching

Propensity score matching is used in non-experimental studies (i.e., studies in which students were not randomized to outreach or control) to balance the observed characteristics between treated and untreated students. It involves estimating a *propensity score*, which is the probability that a student would have been exposed to outreach, conditional on a set of observable characteristics. This propensity score is then used to match treated students to control students with similar estimated propensity scores, resulting in a control group that is demographically similar to the outreach group. Propensity score matching allows us to more accurately evaluate the impact of the outreach than a simple comparison of outcomes between those students who received the outreach and those who did not.

We estimated the propensity score as a function of student-level characteristics available from the Common App data, including: include race/ethnicity, age, gender, English spoken at home, dependent status, number of high schools attended, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator, whether they had a sibling in college, and whether they submitted at least one Common App application before the start of outreach.

To increase balance on our covariates, we placed additional restrictions on our matching algorithm to exact match on specific variables, such as students' high school. Exact matching forced the matching algorithm to *only* find potential matches for treated students in the same high school. This allowed us to control for the fact that students across different high schools have varied school experiences; therefore, matching within schools provides more reasonable matched control students.

Given the algorithm we used, it is possible for one control student to be a perfect match for more than one treatment student. Therefore, we allowed the matching algorithm to match an outreach student to multiple control students. Where this occurred, the control student was up-weighted in our analysis to essentially be "counted" as a comparison for numerous treated students. After concluding our matching, we had a final outreach group of 99,593 students matched to 61,553 control students. @tbl-balance presents balance on student characteristics before and after our matching procedure. After matching, we found no difference above 0.1 standardized mean difference, a commonly accepted benchmark for achieving balance. For a technical explanation of our matching approach, please refer to Appendix A.

## Data

Common App and partners selected for outreach all students from the high school class of 2020 who met two specific criteria: 1) they would be first-generation college students, and 2) they had a low family income, as indicated by qualifying for a Common App fee waiver. In total, the outreach targeted nearly 174,000 students in the class of 2020.

We received student-level data from the Common App for the entire cohort of students who had created a Common App account and had intended to apply to college -- hoping to enroll in fall 2020 -- including students who were selected for the outreach $(n = 173,776)$ and those who were not $(n = 1,229,232)$, for a total of nearly 1.5 million student records.

To evaluate the effectiveness of the outreach campaign, our analysis relied on matching students selected to receive outreach to similar students in the same high school who were not selected for outreach. In particular, some Common App students met one but not both criteria for inclusion in the outreach (i.e., first-generation college student *or* qualified for a fee-waiver). We use these students as our key source of comparison in the analyses. Therefore, our outreach ("treatment") group includes students who met both inclusion criteria (i.e., first-generation college student *and* qualified for a fee-waiver) while our control students met one but not *both* criteria.

Once we cleaned and subset the data to match the outreach inclusion criteria, we arrived at a final analytic sample of 142,837 students who were targeted for the outreach and 263,399 students who were not treated and therefore qualified as potential control students.

## Analytic strategy

In this appendix, we provide a technical explanation of our analytic approach to constructing our matched control group using propensity score matching. Propensity score matching allows us to balance observed characteristics between treated and untreated students, leading to a more accurate estimate of the impact of the outreach.

We begin by estimating a propensity score, defined as the probability that a student would have been exposed to outreach, conditional on a set of observable characteristics. Our propensity score model took the following general form @eq-int-ps:

$$
Outreach_{is} = \beta_{0} + \beta_{1}X + \lambda_{is}
$$ {#eq-int-ps}

Where $outreach_{i.s}$ represents a binary indicator coded as 1 for students who received the outreach and 0 if a student did not. $X$ is a vector of student level characteristics. These include age, gender, English spoken at home, dependent flag, number of high schools attended, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator, sibling college indicator, submitted at least one Common App application before start of outreach, and race/ethnicity indicators.

We also included $(\lambda)$, which represents a vector of covariates for which we exact matched students on. These include students' high school, underrepresented minority indicator, an indicator for submitting at least one Common App application before the start of outreach, and missing indicators for high school GPA and SAT/ACT performance. Exact matching on these variables allows us to match outreach students to control students who *exactly* match them on the set of variables.

It is possible for one control student to be a perfect match for more than one treatment student. Therefore, we allow the matching algorithm to match an outreach student to multiple control students (i.e., matching with replacement). Additionally, we restrict matches to within .50 standard deviations of a propensity score. This allows us to guard against having treatment students matched with control students with a large difference in propensity scores.

To examine how well our matching procedure was able to balance student characteristics, we look at the overall distribution of the propensity score among treatment and untreated students as well as covariate balance before and after matching. @fig-psdist presents the propensity score distribution between treatment and control students before and after matching. Overall, our matching procedure did an excellent job matching treated students to control students, as indicated by the overlap in the distributions on the right panel.

In addition to analyzing the distributional differences in the propensity score, we also looked at baseline characteristics between treatment and control before and after matching. @tbl-balance compares balance of student characteristics before and after matching. Overall, control group students (who are either "low-income" or "first generation" but not both) had higher GPA class rank (70.1% vs. 64.3%) and SAT scores (794.9 vs. 671.3) than treatment group students (who are both "low-income" and "first generation"). The treatment group also included a substantially larger percentage of minority students (28% Black and 41% Latinx) than the control group (19% Black and 23% Latinx). We achieve excellent balance on all covariates included in our matching approach, with no standard mean difference below 0.1. Our final matched sample includes a treatment group consisting of 99,593 students and a matched control of 61,553.

To estimate the impact of outreach on student outcomes, we ran a series of regression models. Specifically, we regressed each outcome on an outreach indicator and student-level characteristics. We also included weights to account for our matching approach.[^03-commonapp_over-1] Our regressions took the following general form[^03-commonapp_over-2] @eq-out:

[^03-commonapp_over-1]: Matching weights were constructed to account for our matching approach that allowed multiple control students to be matched to treated students. Each treated unit gets a weight of 1, while each control student is weighted as the sum of the inverse of the number of control units matched to the same treated unit across its matches.

[^03-commonapp_over-2]: We used robust standard errors clustered at the high school level.

$$
Y_{is} = \beta_{0} + \beta_{1}Outreach_{is} + X\theta + \lambda_s + \epsilon_{is}
$$ {#eq-out}

Where $Y_{is}$ represents our outcome of interest for student $i$ in school $s$. $Outreach$ is a binary indicator coded as 1 for students who received the outreach and 0 if a student did not. $X$ is a vector of student level characteristics such as age and gender. In addition we included high school fixed effects $(\lambda)$ which soak up any remaining variation in the outcome due to differences across high schools. $\beta_{1}$ is our coefficient of interest and represents the mean controlled difference in the outcome between those who received the outreach and those who did not.

Note that although we took a robust matching approach in constructing our control group, there could still be differences between our outreach and control group on student-level characteristics. Therefore, by including the vector of student level covariates $(X)$ in our regressions, we can account for any remaining imbalance between student characteristics that we observe and increase the precision of our impact estimates.[^03-commonapp_over-3]

[^03-commonapp_over-3]: This is commonly referred to as a "doubly robust" approach.

### Limitations

While this matching procedure was successful, we want to highlight the limitations in our ability to attribute a causal relationship between the outreach and the effects we estimate. Given that students were not randomly assigned to the outreach, we cannot make causal claims about the effectiveness of the outreach. However, our robust matching approach allows us to reduce some -- but not all -- the bias that could exist in explaining the relationship between receiving outreach and outcomes. Note that we are only matching on *observable* characteristics. There could be *unobservable* characteristics that the matching procedure cannot consider that could influence outcomes absent the intervention.

Furthermore, important observable differences do remain between the outreach group and the comparison group, even after matching. Students selected for outreach were first-generation *and* low-income, while control students were either first-generation *or* low-income. The outreach team selected students in this manner to reach as many students as possible, specifically students who would likely benefit from this sort of outreach. Although this was a wise approach for targeting students in need of support, it created some analytic obstacles for our impact analysis that can't be remedied through matching. In particular, in any matched pair of low-income students, the treatment group student is first-generation and the control group student is not, and similarly, in any matched pair of first-generation students, the treatment group student is low-income and the control group student is not.

Students in the outreach group have two factors that -- due to an array of systemic issues -- may disadvantage them in terms of college enrollment. Therefore, we may expect that -- even absent the intervention -- students in the outreach group likely have lower college enrollment rates than those who did not receive the outreach. Given how the outreach groups were defined, we cannot observe college enrollment outcomes for control students who were first-generation *and* low-income, which would be the natural comparison for our outreach group. This is because, for the class of 2020, the intervention was targeted to *all* students who met these two criteria. After presenting our findings, we discuss two different strategies we used to investigate what the differences between these two groups might have been absent the chatbot outreach. Overall, we find that students who met both factors had somewhat lower enrollment rates than those who exhibit only one of the two factors

## Preliminary Results

In the following section, we present key findings from our impact analysis. We primarily focus on college application submission and enrollment in the fall term after students graduate high school. Additionally, we analyzed whether effects varied according to student characteristics and engagement in the chatbot communication. We specifically look at impacts for racially marginalized students, students who opted out of the chatbot outreach, and students who had a high level of engagement with the chatbot.

### College Application Submission

> *What is the impact of being targeted for outreach on college application submission?*

@tbl-submit shows the impact of the outreach on submitting at least one college application via the Common App. The *Differential* row refers to the difference in the mean outcome between those students who were targeted for the outreach and their demographically matched controls. For example,the first column shows the impact of the intervention on overall college application submission. Students targeted for outreach had somewhat lower application submission rates than their matched controls. 86.1% of the control group (see *Control Mean* row) submitted at least one college application, while 84.7% of outreach students did so. This differential is equal to around -1.5 percentage points.

Next, we analyzed whether impacts varied based on whether a student submitted at least one college application before or after the start of the intervention. The outreach had no impact on submitting at least one application prior to the start of the intervention, as expected. However, outreach students were less likely to submit an application after the start of the intervention (-1.3 percentage point difference).

### Overall College Enrollment

> *What is the impact of the outreach on college enrollment?*

Next, we present the effects on college enrollment outcomes (@tbl-overenroll). Students in the outreach group had somewhat lower fall 2020 enrollment rates compared to the control group. 76.7% of students in the outreach group enrolled in college in fall 2020, compared to 78.7% of control students, a 2 percentage point differential. We observed effects of a similar magnitude across all other terms.

Additionally, we explored if the outreach impacted whether a student took a gap semester or year. The outreach did not seem to impact whether students took a gap semester. However, we observed a slight increase in outreach students taking a gap year. Olli and the CAC advisors provided no information or advice about taking time off before enrolling in college, so it seems unlikely that the outreach influenced these choices given the underlying uncontrolled differences between treatment and control groups.

We further unpacked enrollment impacts by subsetting our sample to only students who had submitted no college applications prior to the start of the intervention. Given the timing of the outreach in late spring, these students missed most of the college application deadlines and therefore could benefit from this kind of outreach. However, the outreach had no impact across all enrollment outcomes (@tbl-overenroll_submit).

### Fall 2020 College Enrollment

The Common App and its partners were primarily interested in immediate college enrollment after students completed high school. Therefore, we analyzed the impact of the outreach on fall 2020 enrollment by 4-year versus 2-year institutions, private versus public, and full-time enrollment (@tbl-20enroll). The somewhat lower enrollment we observed for outreach students compared to students who did not receive the outreach was likely driven by students forgoing enrolling in 4-year institutions -- specifically 4-year privates (-3.3 percentage point difference) -- and enrolling in 2-year institutions (1.9 percentage point difference).The CAC advisors sometimes suggested two-year colleges to students who expressed concerns about college affordability but did not otherwise take any position on choosing between a two-year and a four-year college.

Additionally, outreach students had lower full-time enrollment rates -- 3 percentage points -- than control students (66.8%).

### Racially Marginalized Students

Next, we examined whether the outreach had a differential impact on students who belonged to a racially marginalized group. We defined a student as racially marginalized if a student self-identified as non-white or bi/multi-racial.

In @tbl-20enrollurm we present the impact of the outreach on fall 2020 college enrollment outcomes. We observed impacts of a similar scale as the entire sample. Racially marginalized students in the outreach group had relatively lower fall 2020 enrollment. There was a modest negative difference in enrollment in fall 2020 of around 2.1 percentage points, specifically driven by outreach students not enrolling at 4-year institutions by around -4.4 percentage points, but instead enrolling at 2-year institutions (2.2 percentage point difference).

### Outreach Participation

Using data from the qualitative analysis team about student engagement with the bot, including whether students decided to opt-out of receiving outreach from Oli. We constructed high engagement and opt out measures. Specifically, we defined high engagers as a student in the top 25th percentile of the total number of text messages sent throughout the outreach. We created the opt-out indicator by flagging students who explicitly messaged "STOP" to Oli at any point during the outreach or received a "goodbye" message from Oli, indicating that the student had requested to opt-out .[^03-commonapp_over-4]

[^03-commonapp_over-4]: Due to data quality issues, we received text message data for 70% of the outreach group. Furthermore, engagement across the intervention was relatively low. On average, students sent around 8 messages throughout the 38 weeks of the outreach. For a thorough explanation of the text analysis, please refer to Part II of this report.

### Opt-Out

Throughout the outreach campaign, students had the option to opt-out of receiving outreach by directly messaging Oli. Around 16% of students requested to opt out. In @tbl-20enrollopt we examine to what extent impacts varied among students who opted out. Across all outcomes, we see no effect on college enrollment. This finding is not surprising, given that most of the students who opted out did so in the first few weeks of the intervention and therefore received little to no communication from the chatbot.

### Oli Engagement

A final question we explored was whether impacts varied for those who engaged highly with Oli, i.e., those in the top 25th percentile of total messages sent throughout the outreach. Due to the low engagement throughout the intervention, a student who sent more than 9 messages was flagged as a "high" engager, which equaled around 17% of all outreach students.

@tbl-20enrolleng presents results for students with high engagement throughout the outreach. As opposed to our overall modest negative impacts for the whole sample, here we found a slightly positive impact on fall 2020 enrollment for highly engaged students, around a 3 percentage point improvement over the matched controls. Students who engaged with Oli at a high rate were, on average, more likely female, came from a racially marginalized group, and had slightly lower SAT/ACT performance than students who didn't have high engagement with the chatbot. Furthermore, these students also had higher rates of college application submission than non-highly engaged students.

### Enrollment Differentials in Context

We want to underscore that important, observable differences remain between the outreach group and the comparison group -- even after matching. As mentioned previously, the students selected for outreach were first-generation *and* low-income, while the control students were first-generation *or* low-income. This presented analytic obstacles in estimating outreach impacts.

In this section, we outline two different strategies we took to investigate what differences between these two groups might have been absent the chatbot outreach.

#### High School Longitudinal Study of 2009

First, we used the High School Longitudinal Study of 2009 (HSLS-09), a nationally representative sample of 9th graders in 2009 who were observed through 2016. The HSLS-09 dataset includes information on college-going. We subsetted the HSLS-09 data to a sample of students who had indicated college interest in 9th grade and had submitted at least one college application. This allowed us to mimic -- although imperfectly -- our 2020 Common App cohort of students who were college intending.

Next, we calculated enrollment differentials for first-generation *and* low-income students and first-generation *or* low-income students. In our 2020 cohort, low-income was defined as qualifying for a Common App fee waiver. Given the information available in the HSLS-09, we defined low-income as a student's family income falling below 130% of the poverty line (i.e., qualified for free or reduced lunch).

Overall, we found that students who were first-generation and low-income had lower college enrollment rates than students with only one of those characteristics. Students who were first-generation *and* low-income had a college enrollment rate of 79.1%. In comparison, students who exhibited only one of these factors had an enrollment rate of around 84.2% (a -5.1 percentage point difference).

Drawbacks of relying on the HSLS-09 as a source for informing this differential include its age (it observes a cohort of students who completed high school several years prior to 2020) and differences in how we define the subsample of students, relative to the focal groups of interest in our analysis of the Common App data.Therefore, we turn to another data source to generate an additional comparison.

#### Common App 2021 Cohort

During the 2021 school year, Common App conducted an unrelated randomized controlled study (RCT) with a cohort of students similar to our 2020 sample. We were able to capitalize on the sample employed in this RCT to further investigate enrollment differentials. We worked with Common App to receive high-level descriptives for the cohort of students who did not receive the 2021 intervention. Specifically, we examined fall 2021 enrollment overall and disaggregated by 4-year versus 2-year institutions for students in the 2021 study control group. These differentials allowed us to observe enrollment outcomes for first-generation *and* low-income students and first-generation *or* low-income students from the class of 2021. Unlike the HSLS-09 dataset, the 2021 Common App dataset allows us to define low-income similarly to our 2020 cohort (i.e., qualified for a Common App fee waiver).

Overall, we found that students who met both factors had somewhat lower enrollment rates than those who exhibit only one of the two factors. Students who were both first-generation *and* low-income had a fall 2021 enrollment rate of 72%, while students who only exhibited one of these factors had a 73% enrollment rate (a -1 percentage point difference).

Ideally, we would have matched students in our 2020 sample to demographically similar students in the 2021 sample, allowing us to estimate the group differentials and adjust our impact estimates directly. Unfortunately, this was not possible due to data sharing agreements. However, we were able to reduce the 2021 sample to students who attended high schools in our final matched 2020 sample. We found a similar enrollment differential in fall 2021 of around -1 percentage point.

Based on the differentials of both these data sources, we conclude that -- absent any intervention -- students who are first-generation *and* low-income have lower college-going rates than those who only hold one of those identities. Therefore, we reason that absent the intervention we would expect that students in the outreach group would have lower college enrollment rates than the comparison group, with differences on the order of -1 to -5 percentage points. These differences suggest that to find a positive effect, the impact of the outreach would have had to be larger than these differentials. Therefore, the modest negative enrollment for outreach students we estimate for the entire sample (-2 percentage points) likely reflect these differentials -- and not -- detrimental effects of the chatbot outreach.

## Looking Ahead

NEED TO TALK ABOUT IN FUTURE WORK THAT I PLAN TO DO SENSITIVITY ANALYSIS

The outreach undertaken by Common App and its partners cast a wide net in hopes of helping students through the typically challenging transition to college during the uncertainty of the COVID-19 pandemic. As part of our evaluation, we conducted a quantitative impact analysis to investigate whether the outreach improved students' college-going outcomes and also a qualitative text analysis to explore students' engagement with the chatbot and CAC advisers. As discussed in detail throughout this report, the core analytic approach to our impact analysis relied on comparisons between observationally similar students who nevertheless differed in a critical way. Those in the treatment group were both first-generation *and* from low-income households. Those in the comparison group had one both not both of these characteristics.

Historical evidence (see page 10) suggests that low family income and status as a first-generation college student serve as complementary risk factors for not enrolling in college. On average, high school seniors who are first-generation *and* low-income are less likely to enroll in college than those who are either first-generation *or* low-income but not both.

While the design choice to provide outreach to all students in the graduating class of 2020 directed services to the subgroup of students that were likely most at risk in the early stages of the pandemic, it also adds an additional layer of complexity to the task of evaluating the effect of this outreach. Since students with two risk factors all received outreach, any contemporaneous comparison group will consist of students facing fewer barriers on average to college enrollment.

In the absence of outreach, students in any comparison group can be expected to be more likely to enroll in college than those selected for the intervention. That is, a typical "treatment" vs. "control" group comparison likely leads to bias and an underestimate of the effects of the outreach on college enrollment. The large size of the intervention and the availability of Common App data for students who were not offered outreach enabled us to estimate the difference in enrollment rates for "treatment" vs. "control" groups with standard errors well less than 1 percentage point. Still, large sample sizes cannot compensate on their own for underlying differences in these two groups of students.

We used propensity score matching to create an analysis sample of students who received outreach that is best suited for comparison to a similar group of students who were not offered outreach. More specifically, our matching procedure identified pairs of students who did and did not receive outreach where each pair attended the same high school and are broadly similar in terms of six demographic variables and four academic indicators. To the degree that first-generation *and* low-income students face greater barriers than first-generation *or* low-income students do, using these variables in the matching procedure should help to reduce the underlying difference in college enrollment rates for treatment and control group students expected in the absence of the intervention. Nevertheless, we still anticipated that within each matched pair, the student who received outreach would face greater barriers to college enrollment and that a comparison of enrollment rates for those in matched pairs would still underestimate the effect of advising.

Despite these challenging issues, it was still quite plausible that our evaluation would find statistically significant evidence that virtual advising increased college enrollment in 2020. One recent multi-district study estimated a 5.2 percentage point increase in four-year college enrollment as the result of text-based FAFSA outreach and support from students' own high school counselors.[^03-commonapp_over-5] An effect of that size could well have been enough to provide a positive and significant result in this study. On the other hand, recent studies of similar outreach and support implemented at scale have found much smaller effects of virtual advising than in-person advising designed to deliver the same kind of support.[^03-commonapp_over-6][^03-commonapp_over-7] Overall and based on our empirical results, we conclude that the chatbot campaign had no impact on the targeted class of 2020 students submitting college applications or enrolling in college.

[^03-commonapp_over-5]: James, G., Witten, D., Hastie, T., & Tibshirani, R. (2017). An introduction to statistical learning with applications in R. Springer.

[^03-commonapp_over-6]: Avery, C., Castleman, B.L., Hurwitz, M., Long, B.T, and Page, L.C. (2021) "Digital messaging to improve college enrollment and success," Economics of Education Review, Elsevier, vol. 84(C).

[^03-commonapp_over-7]: Phillips, M., and Reber, S. (2022). "Does Virtual Advising Increase College Enrollment? Evidence from a Random-Assignment College Access Field Experiment." American Economic Journal: Economic Policy, 14 (3): 198-234.

The limited engagement of students with the bot likely explains these results. While some students were asking the bot important questions about how to enroll in college, decipher financial aid letters, and choose a major, most students did not message Oli in substantively meaningful ways. On average, students sent 8 text messages throughout the 38 week intervention, while 2.5% of students messaged a CAC adviser. A sizable portion of the study population--16%--opted out of the intervention and thus did not receive all of Oli's guidance. However, there was evidence to suggest that the chatbot had a positive impact on college enrollment for students who were highly engaged with the bot during the intervention. This group of highly engaged students may warrant further investigation, as they could shed light on what types of conversations with the bot were most helpful in supporting their postsecondary transition. However, with an intervention that cast such a wide net and that provided relatively general guidance related to college-going processes, it is perhaps unsurprising that the overall effects of the outreach were null.

Taken together, we reasoned that this outreach faced an uphill battle to improve outcomes beyond the differentials that exist absent the intervention. Even though we cannot know what the true causal impact of the outreach was, the evidence we gathered leads us to conclude that the outreach likely neither helped nor harmed students in applying to and enrolling in college.

\newpage

## Tables and Figures

\newpage

|                                                   |           |         | **Before Matching** |           |         | **After Matching** |
|------------------|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
|                                                   | Treatment | Control |    Std.Mean.Diff    | Treatment | Control |   Std.Mean.Diff    |
|                                                   |           |         |                     |           |         |                    |
| Age                                               |  17.082   | 17.023  |        0.118        |   17.05   | 17.025  |       0.050        |
| Male                                              |   0.363   |  0.376  |        0.029        |   0.369   |  0.357  |       0.024        |
| English spoken at home                            |   0.562   |  0.558  |        0.009        |   0.569   |  0.573  |       0.009        |
| Has dependent                                     |   0.011   |  0.007  |        0.042        |   0.009   |  0.009  |       0.008        |
| Attended \> 1 High School                         |   0.181   |  0.161  |        0.041        |   0.164   |  0.166  |       0.003        |
| GPA rank                                          |   0.643   |  0.701  |        0.150        |   0.698   |  0.705  |       0.018        |
| Missing GPA rank                                  |   0.238   |  0.207  |        0.071        |   0.178   |  0.178  |       0.000        |
| SAT score                                         |   671.3   | 794.868 |        0.230        |  712.224  | 712.861 |       0.001        |
| Missing SAT Score                                 |   0.376   |  0.317  |        0.122        |   0.347   |  0.347  |       0.000        |
| College credit exams                              |   0.708   |  1.135  |        0.222        |   0.806   |  0.848  |       0.022        |
| TOEFL                                             |   0.000   |  0.001  |        0.093        |   0.000   |  0.000  |       0.009        |
| Sibling attended college                          |   0.337   |  0.387  |        0.105        |   0.353   |  0.345  |       0.017        |
| Submitted one college application before outreach |   0.777   |  0.796  |        0.044        |   0.853   |  0.853  |       0.000        |
| American Indian/Alaskan Native                    |   0.005   |  0.003  |        0.021        |   0.003   |  0.003  |       0.003        |
| Asian                                             |   0.084   |  0.091  |        0.027        |   0.096   |  0.093  |       0.010        |
| Black                                             |   0.28    |  0.185  |        0.213        |   0.287   |  0.307  |       0.045        |
| Latinx                                            |   0.41    |  0.231  |        0.364        |   0.408   |  0.396  |       0.023        |
| Native Hawaiian/Pacific Islander                  |   0.003   |  0.002  |        0.011        |   0.002   |  0.002  |       0.011        |
| White                                             |   0.169   |  0.383  |        0.570        |   0.164   |  0.164  |       0.002        |
| Multi-racial                                      |   0.044   |  0.051  |        0.031        |   0.036   |  0.031  |       0.025        |
| Race unknown                                      |   0.004   |  0.026  |        0.328        |   0.003   |  0.004  |       0.006        |
| Non-resident                                      |   0.000   |  0.028  |        4.261        |   0.000   |  0.000  |       0.042        |
| URM                                               |   0.826   |  0.563  |        0.694        |   0.833   |  0.833  |       0.000        |
|                                                   |           |         |                     |           |         |                    |
| Num.Obs                                           |  142,827  | 263,299 |                     |  99,593   | 61,553  |                    |

: Balance of student characteristics {#tbl-balance }

\newpage

|                          |   Overall    | Before outreach | After outreach |
|--------------------------|:------------:|:---------------:|:--------------:|
| Application Differential | -0.015\*\*\* |      0.004      |  -0.013\*\*\*  |
|                          |   (0.003)    |     (0.003)     |    (0.002)     |
|                          |              |                 |                |
| Control Mean             |    0.861     |      0.848      |     0.036      |
| Num.Obs.                 |    161146    |     161146      |     161146     |
| R2                       |    0.318     |      0.324      |     0.079      |
| FE: school_id            |      X       |        X        |       X        |

: Impacts on submitting at least one college application {#tbl-submit}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement. Baseline covariates include fee waiver indicator, first-generation status, age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator, sibling college indicator, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance. Robust standard errors clustered at the school level, reported in parentheses.

\newpage

|                         |  Fall 2020   | Spring 2021  |  Fall 2021   | Spring 2022  | Gap semester | Gap year  |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential | -0.020\*\*\* | -0.031\*\*\* | -0.033\*\*\* | -0.038\*\*\* |    0.003     | 0.004\*\* |
|                         |   (0.004)    |   (0.005)    |   (0.005)    |   (0.005)    |   (0.002)    |  (0.002)  |
|                         |              |              |              |              |              |           |
| Control Mean            |    0.787     |    0.724     |    0.701     |    0.648     |    0.024     |   0.023   |
| Num.Obs.                |    161146    |    161146    |    161146    |    161146    |    161146    |  161146   |
| R2                      |    0.155     |    0.177     |    0.179     |    0.194     |    0.073     |   0.079   |
| FE: school_id           |      X       |      X       |      X       |      X       |      X       |     X     |

: Impacts on college enrollment outcomes, by term {#tbl-overenroll}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement.Baseline covariates include fee waiver indicator, first-generation status,age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator,sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance.The gap semester outcome is a binary indicator coded as 1 if a student did not enroll in Fall 2020 but did enroll in Spring 2021. The gap year outcome is also a binary indicator coded as 1 if a student did not enroll in Fall 2020 or Spring 2021, but did enroll in Fall 2022. Robust standard errors clustered at the school level, reported in parentheses.

\newpage

|                         | Fall 2020 | Spring 2021 | Fall 2021 | Spring 2022 | Gap semester | Gap year |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential |   0.008   |    0.030    |  -0.007   |    0.016    |    0.001     |  0.000   |
|                         |  (0.016)  |   (0.016)   |  (0.016)  |   (0.016)   |   (0.006)    | (0.006)  |
|                         |           |             |           |             |              |          |
| Control Mean            |   0.683   |    0.605    |   0.593   |    0.528    |    0.036     |  0.041   |
| Num.Obs.                |   14842   |    14842    |   14842   |    14842    |    14842     |  14842   |
| R2                      |   0.311   |    0.338    |   0.337   |    0.344    |    0.224     |  0.248   |
| FE: school_id           |     X     |      X      |     X     |      X      |      X       |    X     |

: Impacts on college enrollment outcomes, by term - Submitted no application prior to intervention {#tbl-overenroll_submit}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement.Baseline covariates include fee waiver indicator, first-generation status,age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator,sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance.The gap semester outcome is a binary indicator coded as 1 if a student did not enroll in Fall 2020 but did enroll in Spring 2021. The gap year outcome is also a binary indicator coded as 1 if a student did not enroll in Fall 2020 or Spring 2021, but did enroll in Fall 2022. Robust standard errors clustered at the school level, reported in parentheses.

\

\newpage

|                         |  Fall 2020   |    4-year    | 4-year public | 4-year private |   2-year    |  Full-time   |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential | -0.020\*\*\* | -0.040\*\*\* |    -0.007     |  -0.033\*\*\*  | 0.019\*\*\* | -0.029\*\*\* |
|                         |   (0.004)    |   (0.005)    |    (0.005)    |    (0.004)     |   (0.003)   |   (0.005)    |
|                         |              |              |               |                |             |              |
| Control Mean            |    0.787     |    0.671     |     0.457     |     0.217      |    0.121    |    0.668     |
| Num.Obs.                |    161146    |    161146    |    161146     |     161146     |   161146    |    161146    |
| R2                      |    0.155     |    0.207     |     0.173     |     0.141      |    0.145    |    0.175     |
| FE: school_id           |      X       |      X       |       X       |       X        |      X      |      X       |

: Impacts on Fall 2020 college enrollment outcomes {#tbl-20enroll}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement. Baseline covariates include fee waiver indicator, first-generation status, age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator, sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance. Robust standard errors clustered at the school level, reported in parentheses.

\newpage

|                         |  Fall 2020   |    4-year    | 4-year public | 4-year private |   2-year    |  Full-time   |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential | -0.021\*\*\* | -0.044\*\*\* |    -0.007     |  -0.037\*\*\*  | 0.022\*\*\* | -0.034\*\*\* |
|                         |   (0.005)    |   (0.006)    |    (0.007)    |    (0.006)     |   (0.004)   |   (0.006)    |
|                         |              |              |               |                |             |              |
| Control Mean            |    0.784     |    0.661     |     0.452     |     0.212      |    0.129    |    0.661     |
| Num.Obs.                |    97537     |    97537     |     97537     |     97537      |    97537    |    97537     |
| R2                      |    0.160     |    0.213     |     0.181     |     0.144      |    0.152    |    0.180     |
| FE: school_id           |      X       |      X       |       X       |       X        |      X      |      X       |

: Impacts on Fall 2020 college enrollment outcomes - Racially marginalized students {#tbl-20enrollurm}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement. Baseline covariates include fee waiver indicator, first-generation status, age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator, sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance. Robust standard errors clustered at the school level, reported in parentheses.

\newpage

|                         | Fall 2020 | Spring 2021 | Fall 2021 | Spring 2022 | Gap semester | Gap year |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential |  -0.017   |   -0.016    |  -0.011   |   -0.011    |    -0.001    |  0.006   |
|                         |  (0.010)  |   (0.011)   |  (0.011)  |   (0.011)   |   (0.004)    | (0.003)  |
|                         |           |             |           |             |              |          |
| Control Mean            |   0.787   |    0.724    |   0.701   |    0.651    |    0.025     |  0.022   |
| Num.Obs.                |   20527   |    20527    |   20527   |    20527    |    20527     |  20527   |
| R2                      |   0.282   |    0.295    |   0.303   |    0.315    |    0.212     |  0.222   |
| FE: school_id           |     X     |      X      |     X     |      X      |      X       |    X     |

: Impacts on college enrollment outcomes - Opt out {#tbl-20enrollopt}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Opt-out was constructed by flagging students who explicitly messaged "STOP" to the bot at any point during the intervention and/or received a "goodbye" message from Oli, indicating that they had requested to opt out. Due to data quality issues we only have text message data for 70% of all treated students. Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement.Baseline covariates include fee waiver indicator, first-generation status,age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator,sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance.The gap semester outcome is a binary indicator coded as 1 if a student did not enroll in Fall 2020 but did enroll in Spring 2021. The gap year outcome is also a binary indicator coded as 1 if a student did not enroll in Fall 2020 or Spring 2021, but did enroll in Fall 2022. Robust standard errors clustered at the school level, reported in parentheses.

\newpage

|                         | Fall 2020 | 4-year  | 4-year public | 4-year private |   2-year    | Full-time |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential | 0.026\*\* |  0.002  |   0.032\*\*   |  -0.032\*\*\*  | 0.024\*\*\* |   0.005   |
|                         |  (0.009)  | (0.010) |    (0.011)    |    (0.009)     |   (0.007)   |  (0.010)  |
|                         |           |         |               |                |             |           |
| Control Mean            |   0.793   |  0.674  |     0.461     |     0.215      |    0.123    |   0.676   |
| Num.Obs.                |   26281   |  26281  |     26281     |     26281      |    26281    |   26281   |
| R2                      |   0.256   |  0.304  |     0.279     |     0.253      |    0.251    |   0.272   |
| FE: school_id           |     X     |    X    |       X       |       X        |      X      |     X     |

: Impacts of text message engagement on Fall 2020 college enrollment - High text engagement {#tbl-20enrolleng}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: High engagement indicator is coded as 1 for students who are in the top 25th percentile (sent more than 9 text messages) of total number of text messages students sent throughout the intervention. Due to data quality issues we only have text message data for 70% of all treated students. Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement.Baseline covariates include fee waiver indicator, first-generation status,age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator,sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance.Robust standard errors clustered at the school level, reported in parentheses.

\newpage

![Propensity score distribution](figures/ps_dist.png){#fig-psdist alt="Propensity score distribution" width="340"}
