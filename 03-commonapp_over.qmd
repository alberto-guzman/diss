# Paper 2: Navigating college enrollment during the COVID-19 pandemic: examining the effectiveness of an artificially intelligent chatbot in helping students navigate the road to college

## Introduction

IN LINDSAY REVIEW

## Literature Review

IN LINDSAY REVIEW

## Methods

## Research Design

During 2019-20 college adminission cycle, we partnered with the Common App, Mainstay, and the College Advising Corps to evaluate the effectivens of a chatbot campaign to promote college application submission and college enrollment among the graduating class of 2020 college intending seniors. This campaign specifically targetted students who were using the Common Application to submit college applicaiton. Common App which is a non-profit membsership organization representing more than 1,000 insitutions that allows students to apply streamline their college application process by sumitting a single applicaiton that is accepted by all member instituions. Member insitutions are diverse, comprising of public and private colleges and universities across the US and 20 countries, primarily 4-year insituions. 

### Data and Sample

The chatbot campaign focused on graduating high school seniros across the US who where first-generation and low-income [^1]. These students where submitting college applciations in order to enroll in college in Fall 2020, in the midst of the COVID-19 pandemic. Our analytic sample included students who lived in the US, had a valid cell-phone number, graduated high school in 2022, and where either first-genration or qualified for a fee-waive. We further reduced our analytic sample to only include high schools in which at least one student who was targetted for outreach attended. Our final analytic sample included nearly half a million students (N = 406,236), with 142,837 who were targeted for outreach and 263,399 who were note. These students attended a total of 15,277 high school across the US. To our knowledge this is the largest chatbot study of its kind in higher education and represents nearly 13% of all stuent who applied to college using the Common App in 2019-2020.

[^1]: We identify as a student being low-income if they qualified for a Common App fee-waiver.

We utilized several different data sources to investitage the *impact*? of the chatbot oureach on wether students applied and enrolled in college. First, we utilized administrative records from the Common App that provided a rich data source of any and all information that a student provided on their Common App application including, student demograhpics, high school academic ahcievement, and college entrance exams. Additionally, we received information on the specific high school a student atteneded. This allowed us to look for suitable control students for outreach students within the same high school. Given, we might expect that college-intentind students within the same high school have similar schooling experience and access to college facilitating supports that students across high schools. 

Second, Mainstay provided access to the chatbot platform that was utilized to provide outreach to students. This platform captured rich data on the content and timing of the chatbot communication among students the chatbot and CAC advisers. Particularly useful for our anlayais, this data included logs of every message that was sent throughout the outreach. Using this data we generated variables that captured student opt-out request and engagement. Finally, we matched students in our analytic file to data from the National Student Clearning in order to observe if and where students enrolled in college in fall 2020 and wether they persisted through subsequent terms. 

In Table X, we present sample descriptive statistics for students who received the oureach and those who did not. Students who were selected for the outreach differ systematicaly on important orbservable characteristis that would likely bias our findings. 

IMportant to note.. 

Students selected for outreach are more likely to have lower high school GPA, SAT/ACT score, completed less college credit exam than students who were not selected for outreach. In additiona, students in the outreach groups were more likely to self-identify as racially marginalized (83%) than non-outreach students (56%). 







It is important to note that the outreach team did not randomly assign the outreach for this campaign. Randomly assigning the outreach would ensure that students who received the outreach and those who did not would be balanced on both observable *and* unobservable characteristics. Given the lack of randomization, a simple comparison of outcomes between students who received the outreach and those who did not may -- incorrectly -- conclude that the outreach affected the outcome. To guard against this to the fullest extent possible, we matched students in the outreach group to demographically similar students in the same high school who were not treated. These matched students are then observationally similar to students in the outreach group and, therefore, a reasonable comparison group. Analytically, we do this matching via a procedure termed propensity score matching.

### Matching

Propensity score matching is used in non-experimental studies (i.e., studies in which students were not randomized to outreach or control) to balance the observed characteristics between treated and untreated students. It involves estimating a *propensity score*, which is the probability that a student would have been exposed to outreach, conditional on a set of observable characteristics. This propensity score is then used to match treated students to control students with similar estimated propensity scores, resulting in a control group that is demographically similar to the outreach group. Propensity score matching allows us to more accurately evaluate the impact of the outreach than a simple comparison of outcomes between those students who received the outreach and those who did not.

We estimated the propensity score as a function of student-level characteristics available from the Common App data, including: include race/ethnicity, age, gender, English spoken at home, dependent status, number of high schools attended, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator, whether they had a sibling in college, and whether they submitted at least one Common App application before the start of outreach.

To increase balance on our covariates, we placed additional restrictions on our matching algorithm to exact match on specific variables, such as students' high school. Exact matching forced the matching algorithm to *only* find potential matches for treated students in the same high school. This allowed us to control for the fact that students across different high schools have varied school experiences; therefore, matching within schools provides more reasonable matched control students.

Given the algorithm we used, it is possible for one control student to be a perfect match for more than one treatment student. Therefore, we allowed the matching algorithm to match an outreach student to multiple control students. Where this occurred, the control student was up-weighted in our analysis to essentially be "counted" as a comparison for numerous treated students. After concluding our matching, we had a final outreach group of 99,593 students matched to 61,553 control students. @tbl-balance presents balance on student characteristics before and after our matching procedure. After matching, we found no difference above 0.1 standardized mean difference, a commonly accepted benchmark for achieving balance. For a technical explanation of our matching approach, please refer to Appendix A.

## Data

Common App and partners selected for outreach all students from the high school class of 2020 who met two specific criteria: 1) they would be first-generation college students, and 2) they had a low family income, as indicated by qualifying for a Common App fee waiver. In total, the outreach targeted nearly 174,000 students in the class of 2020.

We received student-level data from the Common App for the entire cohort of students who had created a Common App account and had intended to apply to college -- hoping to enroll in fall 2020 -- including students who were selected for the outreach $(n = 173,776)$ and those who were not $(n = 1,229,232)$, for a total of nearly 1.5 million student records.

To evaluate the effectiveness of the outreach campaign, our analysis relied on matching students selected to receive outreach to similar students in the same high school who were not selected for outreach. In particular, some Common App students met one but not both criteria for inclusion in the outreach (i.e., first-generation college student *or* qualified for a fee-waiver). We use these students as our key source of comparison in the analyses. Therefore, our outreach ("treatment") group includes students who met both inclusion criteria (i.e., first-generation college student *and* qualified for a fee-waiver) while our control students met one but not *both* criteria.

Once we cleaned and subset the data to match the outreach inclusion criteria, we arrived at a final analytic sample of 142,837 students who were targeted for the outreach and 263,399 students who were not treated and therefore qualified as potential control students.

## Analytic strategy

In this appendix, we provide a technical explanation of our analytic approach to constructing our matched control group using propensity score matching. Propensity score matching allows us to balance observed characteristics between treated and untreated students, leading to a more accurate estimate of the impact of the outreach.

We begin by estimating a propensity score, defined as the probability that a student would have been exposed to outreach, conditional on a set of observable characteristics. Our propensity score model took the following general form @eq-int-ps:

$$
Outreach_{is} = \beta_{0} + \beta_{1}X + \lambda_{is}
$$ {#eq-int-ps}

Where $outreach_{i.s}$ represents a binary indicator coded as 1 for students who received the outreach and 0 if a student did not. $X$ is a vector of student level characteristics. These include age, gender, English spoken at home, dependent flag, number of high schools attended, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator, sibling college indicator, submitted at least one Common App application before start of outreach, and race/ethnicity indicators.

We also included $(\lambda)$, which represents a vector of covariates for which we exact matched students on. These include students' high school, underrepresented minority indicator, an indicator for submitting at least one Common App application before the start of outreach, and missing indicators for high school GPA and SAT/ACT performance. Exact matching on these variables allows us to match outreach students to control students who *exactly* match them on the set of variables.

It is possible for one control student to be a perfect match for more than one treatment student. Therefore, we allow the matching algorithm to match an outreach student to multiple control students (i.e., matching with replacement). Additionally, we restrict matches to within .50 standard deviations of a propensity score. This allows us to guard against having treatment students matched with control students with a large difference in propensity scores.

To examine how well our matching procedure was able to balance student characteristics, we look at the overall distribution of the propensity score among treatment and untreated students as well as covariate balance before and after matching. @fig-psdist presents the propensity score distribution between treatment and control students before and after matching. Overall, our matching procedure did an excellent job matching treated students to control students, as indicated by the overlap in the distributions on the right panel.

In addition to analyzing the distributional differences in the propensity score, we also looked at baseline characteristics between treatment and control before and after matching. @tbl-balance compares balance of student characteristics before and after matching. Overall, control group students (who are either "low-income" or "first generation" but not both) had higher GPA class rank (70.1% vs. 64.3%) and SAT scores (794.9 vs. 671.3) than treatment group students (who are both "low-income" and "first generation"). The treatment group also included a substantially larger percentage of minority students (28% Black and 41% Latinx) than the control group (19% Black and 23% Latinx). We achieve excellent balance on all covariates included in our matching approach, with no standard mean difference below 0.1. Our final matched sample includes a treatment group consisting of 99,593 students and a matched control of 61,553.

To estimate the impact of outreach on student outcomes, we ran a series of regression models. Specifically, we regressed each outcome on an outreach indicator and student-level characteristics. We also included weights to account for our matching approach.[^03-commonapp_over-1] Our regressions took the following general form[^03-commonapp_over-2] @eq-out:

[^03-commonapp_over-1]: Matching weights were constructed to account for our matching approach that allowed multiple control students to be matched to treated students. Each treated unit gets a weight of 1, while each control student is weighted as the sum of the inverse of the number of control units matched to the same treated unit across its matches.

[^03-commonapp_over-2]: We used robust standard errors clustered at the high school level.

$$
Y_{is} = \beta_{0} + \beta_{1}Outreach_{is} + X\theta + \lambda_s + \epsilon_{is}
$$ {#eq-out}

Where $Y_{is}$ represents our outcome of interest for student $i$ in school $s$. $Outreach$ is a binary indicator coded as 1 for students who received the outreach and 0 if a student did not. $X$ is a vector of student level characteristics such as age and gender. In addition we included high school fixed effects $(\lambda)$ which soak up any remaining variation in the outcome due to differences across high schools. $\beta_{1}$ is our coefficient of interest and represents the mean controlled difference in the outcome between those who received the outreach and those who did not.

Note that although we took a robust matching approach in constructing our control group, there could still be differences between our outreach and control group on student-level characteristics. Therefore, by including the vector of student level covariates $(X)$ in our regressions, we can account for any remaining imbalance between student characteristics that we observe and increase the precision of our impact estimates.[^03-commonapp_over-3]

[^03-commonapp_over-3]: This is commonly referred to as a "doubly robust" approach.

### Limitations

While this matching procedure was successful, we want to highlight the limitations in our ability to attribute a causal relationship between the outreach and the effects we estimate. Given that students were not randomly assigned to the outreach, we cannot make causal claims about the effectiveness of the outreach. However, our robust matching approach allows us to reduce some -- but not all -- the bias that could exist in explaining the relationship between receiving outreach and outcomes. Note that we are only matching on *observable* characteristics. There could be *unobservable* characteristics that the matching procedure cannot consider that could influence outcomes absent the intervention.

Furthermore, important observable differences do remain between the outreach group and the comparison group, even after matching. Students selected for outreach were first-generation *and* low-income, while control students were either first-generation *or* low-income. The outreach team selected students in this manner to reach as many students as possible, specifically students who would likely benefit from this sort of outreach. Although this was a wise approach for targeting students in need of support, it created some analytic obstacles for our impact analysis that can't be remedied through matching. In particular, in any matched pair of low-income students, the treatment group student is first-generation and the control group student is not, and similarly, in any matched pair of first-generation students, the treatment group student is low-income and the control group student is not.

Students in the outreach group have two factors that -- due to an array of systemic issues -- may disadvantage them in terms of college enrollment. Therefore, we may expect that -- even absent the intervention -- students in the outreach group likely have lower college enrollment rates than those who did not receive the outreach. Given how the outreach groups were defined, we cannot observe college enrollment outcomes for control students who were first-generation *and* low-income, which would be the natural comparison for our outreach group. This is because, for the class of 2020, the intervention was targeted to *all* students who met these two criteria. After presenting our findings, we discuss two different strategies we used to investigate what the differences between these two groups might have been absent the chatbot outreach. Overall, we find that students who met both factors had somewhat lower enrollment rates than those who exhibit only one of the two factors

## Preliminary Results

In the following section, we present key findings from our impact analysis. We primarily focus on college application submission and enrollment in the fall term after students graduate high school. Additionally, we analyzed whether effects varied according to student characteristics and engagement in the chatbot communication. We specifically look at impacts for racially marginalized students, students who opted out of the chatbot outreach, and students who had a high level of engagement with the chatbot.

### College Application Submission

> *What is the impact of being targeted for outreach on college application submission?*

@tbl-submit shows the impact of the outreach on submitting at least one college application via the Common App. The *Differential* row refers to the difference in the mean outcome between those students who were targeted for the outreach and their demographically matched controls. For example,the first column shows the impact of the intervention on overall college application submission. Students targeted for outreach had somewhat lower application submission rates than their matched controls. 86.1% of the control group (see *Control Mean* row) submitted at least one college application, while 84.7% of outreach students did so. This differential is equal to around -1.5 percentage points.

Next, we analyzed whether impacts varied based on whether a student submitted at least one college application before or after the start of the intervention. The outreach had no impact on submitting at least one application prior to the start of the intervention, as expected. However, outreach students were less likely to submit an application after the start of the intervention (-1.3 percentage point difference).

### Overall College Enrollment

> *What is the impact of the outreach on college enrollment?*

Next, we present the effects on college enrollment outcomes (@tbl-overenroll). Students in the outreach group had somewhat lower fall 2020 enrollment rates compared to the control group. 76.7% of students in the outreach group enrolled in college in fall 2020, compared to 78.7% of control students, a 2 percentage point differential. We observed effects of a similar magnitude across all other terms.

Additionally, we explored if the outreach impacted whether a student took a gap semester or year. The outreach did not seem to impact whether students took a gap semester. However, we observed a slight increase in outreach students taking a gap year. Olli and the CAC advisors provided no information or advice about taking time off before enrolling in college, so it seems unlikely that the outreach influenced these choices given the underlying uncontrolled differences between treatment and control groups.

We further unpacked enrollment impacts by subsetting our sample to only students who had submitted no college applications prior to the start of the intervention. Given the timing of the outreach in late spring, these students missed most of the college application deadlines and therefore could benefit from this kind of outreach. However, the outreach had no impact across all enrollment outcomes (@tbl-overenroll_submit).

### Fall 2020 College Enrollment

The Common App and its partners were primarily interested in immediate college enrollment after students completed high school. Therefore, we analyzed the impact of the outreach on fall 2020 enrollment by 4-year versus 2-year institutions, private versus public, and full-time enrollment (@tbl-20enroll). The somewhat lower enrollment we observed for outreach students compared to students who did not receive the outreach was likely driven by students forgoing enrolling in 4-year institutions -- specifically 4-year privates (-3.3 percentage point difference) -- and enrolling in 2-year institutions (1.9 percentage point difference).The CAC advisors sometimes suggested two-year colleges to students who expressed concerns about college affordability but did not otherwise take any position on choosing between a two-year and a four-year college.

Additionally, outreach students had lower full-time enrollment rates -- 3 percentage points -- than control students (66.8%).

### Racially Marginalized Students

Next, we examined whether the outreach had a differential impact on students who belonged to a racially marginalized group. We defined a student as racially marginalized if a student self-identified as non-white or bi/multi-racial.

In @tbl-20enrollurm we present the impact of the outreach on fall 2020 college enrollment outcomes. We observed impacts of a similar scale as the entire sample. Racially marginalized students in the outreach group had relatively lower fall 2020 enrollment. There was a modest negative difference in enrollment in fall 2020 of around 2.1 percentage points, specifically driven by outreach students not enrolling at 4-year institutions by around -4.4 percentage points, but instead enrolling at 2-year institutions (2.2 percentage point difference).

### Outreach Participation

Using data from the qualitative analysis team about student engagement with the bot, including whether students decided to opt-out of receiving outreach from Oli. We constructed high engagement and opt out measures. Specifically, we defined high engagers as a student in the top 25th percentile of the total number of text messages sent throughout the outreach. We created the opt-out indicator by flagging students who explicitly messaged "STOP" to Oli at any point during the outreach or received a "goodbye" message from Oli, indicating that the student had requested to opt-out .[^03-commonapp_over-4]

[^03-commonapp_over-4]: Due to data quality issues, we received text message data for 70% of the outreach group. Furthermore, engagement across the intervention was relatively low. On average, students sent around 8 messages throughout the 38 weeks of the outreach. For a thorough explanation of the text analysis, please refer to Part II of this report.

### Opt-Out

Throughout the outreach campaign, students had the option to opt-out of receiving outreach by directly messaging Oli. Around 16% of students requested to opt out. In @tbl-20enrollopt we examine to what extent impacts varied among students who opted out. Across all outcomes, we see no effect on college enrollment. This finding is not surprising, given that most of the students who opted out did so in the first few weeks of the intervention and therefore received little to no communication from the chatbot.

### Oli Engagement

A final question we explored was whether impacts varied for those who engaged highly with Oli, i.e., those in the top 25th percentile of total messages sent throughout the outreach. Due to the low engagement throughout the intervention, a student who sent more than 9 messages was flagged as a "high" engager, which equaled around 17% of all outreach students.

@tbl-20enrolleng presents results for students with high engagement throughout the outreach. As opposed to our overall modest negative impacts for the whole sample, here we found a slightly positive impact on fall 2020 enrollment for highly engaged students, around a 3 percentage point improvement over the matched controls. Students who engaged with Oli at a high rate were, on average, more likely female, came from a racially marginalized group, and had slightly lower SAT/ACT performance than students who didn't have high engagement with the chatbot. Furthermore, these students also had higher rates of college application submission than non-highly engaged students.

### Enrollment Differentials in Context

We want to underscore that important, observable differences remain between the outreach group and the comparison group -- even after matching. As mentioned previously, the students selected for outreach were first-generation *and* low-income, while the control students were first-generation *or* low-income. This presented analytic obstacles in estimating outreach impacts.

In this section, we outline two different strategies we took to investigate what differences between these two groups might have been absent the chatbot outreach.

#### High School Longitudinal Study of 2009

First, we used the High School Longitudinal Study of 2009 (HSLS-09), a nationally representative sample of 9th graders in 2009 who were observed through 2016. The HSLS-09 dataset includes information on college-going. We subsetted the HSLS-09 data to a sample of students who had indicated college interest in 9th grade and had submitted at least one college application. This allowed us to mimic -- although imperfectly -- our 2020 Common App cohort of students who were college intending.

Next, we calculated enrollment differentials for first-generation *and* low-income students and first-generation *or* low-income students. In our 2020 cohort, low-income was defined as qualifying for a Common App fee waiver. Given the information available in the HSLS-09, we defined low-income as a student's family income falling below 130% of the poverty line (i.e., qualified for free or reduced lunch).

Overall, we found that students who were first-generation and low-income had lower college enrollment rates than students with only one of those characteristics. Students who were first-generation *and* low-income had a college enrollment rate of 79.1%. In comparison, students who exhibited only one of these factors had an enrollment rate of around 84.2% (a -5.1 percentage point difference).

Drawbacks of relying on the HSLS-09 as a source for informing this differential include its age (it observes a cohort of students who completed high school several years prior to 2020) and differences in how we define the subsample of students, relative to the focal groups of interest in our analysis of the Common App data.Therefore, we turn to another data source to generate an additional comparison.

#### Common App 2021 Cohort

During the 2021 school year, Common App conducted an unrelated randomized controlled study (RCT) with a cohort of students similar to our 2020 sample. We were able to capitalize on the sample employed in this RCT to further investigate enrollment differentials. We worked with Common App to receive high-level descriptives for the cohort of students who did not receive the 2021 intervention. Specifically, we examined fall 2021 enrollment overall and disaggregated by 4-year versus 2-year institutions for students in the 2021 study control group. These differentials allowed us to observe enrollment outcomes for first-generation *and* low-income students and first-generation *or* low-income students from the class of 2021. Unlike the HSLS-09 dataset, the 2021 Common App dataset allows us to define low-income similarly to our 2020 cohort (i.e., qualified for a Common App fee waiver).

Overall, we found that students who met both factors had somewhat lower enrollment rates than those who exhibit only one of the two factors. Students who were both first-generation *and* low-income had a fall 2021 enrollment rate of 72%, while students who only exhibited one of these factors had a 73% enrollment rate (a -1 percentage point difference).

Ideally, we would have matched students in our 2020 sample to demographically similar students in the 2021 sample, allowing us to estimate the group differentials and adjust our impact estimates directly. Unfortunately, this was not possible due to data sharing agreements. However, we were able to reduce the 2021 sample to students who attended high schools in our final matched 2020 sample. We found a similar enrollment differential in fall 2021 of around -1 percentage point.

Based on the differentials of both these data sources, we conclude that -- absent any intervention -- students who are first-generation *and* low-income have lower college-going rates than those who only hold one of those identities. Therefore, we reason that absent the intervention we would expect that students in the outreach group would have lower college enrollment rates than the comparison group, with differences on the order of -1 to -5 percentage points. These differences suggest that to find a positive effect, the impact of the outreach would have had to be larger than these differentials. Therefore, the modest negative enrollment for outreach students we estimate for the entire sample (-2 percentage points) likely reflect these differentials -- and not -- detrimental effects of the chatbot outreach.

## Looking Ahead

NEED TO TALK ABOUT IN FUTURE WORK THAT I PLAN TO DO SENSITIVITY ANALYSIS

The outreach undertaken by Common App and its partners cast a wide net in hopes of helping students through the typically challenging transition to college during the uncertainty of the COVID-19 pandemic. As part of our evaluation, we conducted a quantitative impact analysis to investigate whether the outreach improved students' college-going outcomes and also a qualitative text analysis to explore students' engagement with the chatbot and CAC advisers. As discussed in detail throughout this report, the core analytic approach to our impact analysis relied on comparisons between observationally similar students who nevertheless differed in a critical way. Those in the treatment group were both first-generation *and* from low-income households. Those in the comparison group had one both not both of these characteristics.

Historical evidence (see page 10) suggests that low family income and status as a first-generation college student serve as complementary risk factors for not enrolling in college. On average, high school seniors who are first-generation *and* low-income are less likely to enroll in college than those who are either first-generation *or* low-income but not both.

While the design choice to provide outreach to all students in the graduating class of 2020 directed services to the subgroup of students that were likely most at risk in the early stages of the pandemic, it also adds an additional layer of complexity to the task of evaluating the effect of this outreach. Since students with two risk factors all received outreach, any contemporaneous comparison group will consist of students facing fewer barriers on average to college enrollment.

In the absence of outreach, students in any comparison group can be expected to be more likely to enroll in college than those selected for the intervention. That is, a typical "treatment" vs. "control" group comparison likely leads to bias and an underestimate of the effects of the outreach on college enrollment. The large size of the intervention and the availability of Common App data for students who were not offered outreach enabled us to estimate the difference in enrollment rates for "treatment" vs. "control" groups with standard errors well less than 1 percentage point. Still, large sample sizes cannot compensate on their own for underlying differences in these two groups of students.

We used propensity score matching to create an analysis sample of students who received outreach that is best suited for comparison to a similar group of students who were not offered outreach. More specifically, our matching procedure identified pairs of students who did and did not receive outreach where each pair attended the same high school and are broadly similar in terms of six demographic variables and four academic indicators. To the degree that first-generation *and* low-income students face greater barriers than first-generation *or* low-income students do, using these variables in the matching procedure should help to reduce the underlying difference in college enrollment rates for treatment and control group students expected in the absence of the intervention. Nevertheless, we still anticipated that within each matched pair, the student who received outreach would face greater barriers to college enrollment and that a comparison of enrollment rates for those in matched pairs would still underestimate the effect of advising.

Despite these challenging issues, it was still quite plausible that our evaluation would find statistically significant evidence that virtual advising increased college enrollment in 2020. One recent multi-district study estimated a 5.2 percentage point increase in four-year college enrollment as the result of text-based FAFSA outreach and support from students' own high school counselors.[^03-commonapp_over-5] An effect of that size could well have been enough to provide a positive and significant result in this study. On the other hand, recent studies of similar outreach and support implemented at scale have found much smaller effects of virtual advising than in-person advising designed to deliver the same kind of support.[^03-commonapp_over-6][^03-commonapp_over-7] Overall and based on our empirical results, we conclude that the chatbot campaign had no impact on the targeted class of 2020 students submitting college applications or enrolling in college.

[^03-commonapp_over-5]: James, G., Witten, D., Hastie, T., & Tibshirani, R. (2017). An introduction to statistical learning with applications in R. Springer.

[^03-commonapp_over-6]: Avery, C., Castleman, B.L., Hurwitz, M., Long, B.T, and Page, L.C. (2021) "Digital messaging to improve college enrollment and success," Economics of Education Review, Elsevier, vol. 84(C).

[^03-commonapp_over-7]: Phillips, M., and Reber, S. (2022). "Does Virtual Advising Increase College Enrollment? Evidence from a Random-Assignment College Access Field Experiment." American Economic Journal: Economic Policy, 14 (3): 198-234.

The limited engagement of students with the bot likely explains these results. While some students were asking the bot important questions about how to enroll in college, decipher financial aid letters, and choose a major, most students did not message Oli in substantively meaningful ways. On average, students sent 8 text messages throughout the 38 week intervention, while 2.5% of students messaged a CAC adviser. A sizable portion of the study population--16%--opted out of the intervention and thus did not receive all of Oli's guidance. However, there was evidence to suggest that the chatbot had a positive impact on college enrollment for students who were highly engaged with the bot during the intervention. This group of highly engaged students may warrant further investigation, as they could shed light on what types of conversations with the bot were most helpful in supporting their postsecondary transition. However, with an intervention that cast such a wide net and that provided relatively general guidance related to college-going processes, it is perhaps unsurprising that the overall effects of the outreach were null.

Taken together, we reasoned that this outreach faced an uphill battle to improve outcomes beyond the differentials that exist absent the intervention. Even though we cannot know what the true causal impact of the outreach was, the evidence we gathered leads us to conclude that the outreach likely neither helped nor harmed students in applying to and enrolling in college.

\newpage

## Tables and Figures

\newpage

|                                                   |           |         | **Before Matching** |           |         | **After Matching** |
|-----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
|                                                   | Treatment | Control |    Std.Mean.Diff    | Treatment | Control |   Std.Mean.Diff    |
|                                                   |           |         |                     |           |         |                    |
| Age                                               |  17.082   | 17.023  |        0.118        |   17.05   | 17.025  |       0.050        |
| Male                                              |   0.363   |  0.376  |        0.029        |   0.369   |  0.357  |       0.024        |
| English spoken at home                            |   0.562   |  0.558  |        0.009        |   0.569   |  0.573  |       0.009        |
| Has dependent                                     |   0.011   |  0.007  |        0.042        |   0.009   |  0.009  |       0.008        |
| Attended \> 1 High School                         |   0.181   |  0.161  |        0.041        |   0.164   |  0.166  |       0.003        |
| GPA rank                                          |   0.643   |  0.701  |        0.150        |   0.698   |  0.705  |       0.018        |
| Missing GPA rank                                  |   0.238   |  0.207  |        0.071        |   0.178   |  0.178  |       0.000        |
| SAT score                                         |   671.3   | 794.868 |        0.230        |  712.224  | 712.861 |       0.001        |
| Missing SAT Score                                 |   0.376   |  0.317  |        0.122        |   0.347   |  0.347  |       0.000        |
| College credit exams                              |   0.708   |  1.135  |        0.222        |   0.806   |  0.848  |       0.022        |
| TOEFL                                             |   0.000   |  0.001  |        0.093        |   0.000   |  0.000  |       0.009        |
| Sibling attended college                          |   0.337   |  0.387  |        0.105        |   0.353   |  0.345  |       0.017        |
| Submitted one college application before outreach |   0.777   |  0.796  |        0.044        |   0.853   |  0.853  |       0.000        |
| American Indian/Alaskan Native                    |   0.005   |  0.003  |        0.021        |   0.003   |  0.003  |       0.003        |
| Asian                                             |   0.084   |  0.091  |        0.027        |   0.096   |  0.093  |       0.010        |
| Black                                             |   0.28    |  0.185  |        0.213        |   0.287   |  0.307  |       0.045        |
| Latinx                                            |   0.41    |  0.231  |        0.364        |   0.408   |  0.396  |       0.023        |
| Native Hawaiian/Pacific Islander                  |   0.003   |  0.002  |        0.011        |   0.002   |  0.002  |       0.011        |
| White                                             |   0.169   |  0.383  |        0.570        |   0.164   |  0.164  |       0.002        |
| Multi-racial                                      |   0.044   |  0.051  |        0.031        |   0.036   |  0.031  |       0.025        |
| Race unknown                                      |   0.004   |  0.026  |        0.328        |   0.003   |  0.004  |       0.006        |
| Non-resident                                      |   0.000   |  0.028  |        4.261        |   0.000   |  0.000  |       0.042        |
| URM                                               |   0.826   |  0.563  |        0.694        |   0.833   |  0.833  |       0.000        |
|                                                   |           |         |                     |           |         |                    |
| Num.Obs                                           |  142,827  | 263,299 |                     |  99,593   | 61,553  |                    |

: Balance of student characteristics {#tbl-balance }

\newpage

|                          |   Overall    | Before outreach | After outreach |
|--------------------------|:------------:|:---------------:|:--------------:|
| Application Differential | -0.015\*\*\* |      0.004      |  -0.013\*\*\*  |
|                          |   (0.003)    |     (0.003)     |    (0.002)     |
|                          |              |                 |                |
| Control Mean             |    0.861     |      0.848      |     0.036      |
| Num.Obs.                 |    161146    |     161146      |     161146     |
| R2                       |    0.318     |      0.324      |     0.079      |
| FE: school_id            |      X       |        X        |       X        |

: Impacts on submitting at least one college application {#tbl-submit}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement. Baseline covariates include fee waiver indicator, first-generation status, age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator, sibling college indicator, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance. Robust standard errors clustered at the school level, reported in parentheses.

\newpage

|                         |  Fall 2020   | Spring 2021  |  Fall 2021   | Spring 2022  | Gap semester | Gap year  |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential | -0.020\*\*\* | -0.031\*\*\* | -0.033\*\*\* | -0.038\*\*\* |    0.003     | 0.004\*\* |
|                         |   (0.004)    |   (0.005)    |   (0.005)    |   (0.005)    |   (0.002)    |  (0.002)  |
|                         |              |              |              |              |              |           |
| Control Mean            |    0.787     |    0.724     |    0.701     |    0.648     |    0.024     |   0.023   |
| Num.Obs.                |    161146    |    161146    |    161146    |    161146    |    161146    |  161146   |
| R2                      |    0.155     |    0.177     |    0.179     |    0.194     |    0.073     |   0.079   |
| FE: school_id           |      X       |      X       |      X       |      X       |      X       |     X     |

: Impacts on college enrollment outcomes, by term {#tbl-overenroll}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement.Baseline covariates include fee waiver indicator, first-generation status,age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator,sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance.The gap semester outcome is a binary indicator coded as 1 if a student did not enroll in Fall 2020 but did enroll in Spring 2021. The gap year outcome is also a binary indicator coded as 1 if a student did not enroll in Fall 2020 or Spring 2021, but did enroll in Fall 2022. Robust standard errors clustered at the school level, reported in parentheses.

\newpage

|                         | Fall 2020 | Spring 2021 | Fall 2021 | Spring 2022 | Gap semester | Gap year |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential |   0.008   |    0.030    |  -0.007   |    0.016    |    0.001     |  0.000   |
|                         |  (0.016)  |   (0.016)   |  (0.016)  |   (0.016)   |   (0.006)    | (0.006)  |
|                         |           |             |           |             |              |          |
| Control Mean            |   0.683   |    0.605    |   0.593   |    0.528    |    0.036     |  0.041   |
| Num.Obs.                |   14842   |    14842    |   14842   |    14842    |    14842     |  14842   |
| R2                      |   0.311   |    0.338    |   0.337   |    0.344    |    0.224     |  0.248   |
| FE: school_id           |     X     |      X      |     X     |      X      |      X       |    X     |

: Impacts on college enrollment outcomes, by term - Submitted no application prior to intervention {#tbl-overenroll_submit}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement.Baseline covariates include fee waiver indicator, first-generation status,age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator,sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance.The gap semester outcome is a binary indicator coded as 1 if a student did not enroll in Fall 2020 but did enroll in Spring 2021. The gap year outcome is also a binary indicator coded as 1 if a student did not enroll in Fall 2020 or Spring 2021, but did enroll in Fall 2022. Robust standard errors clustered at the school level, reported in parentheses.

\

\newpage

|                         |  Fall 2020   |    4-year    | 4-year public | 4-year private |   2-year    |  Full-time   |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential | -0.020\*\*\* | -0.040\*\*\* |    -0.007     |  -0.033\*\*\*  | 0.019\*\*\* | -0.029\*\*\* |
|                         |   (0.004)    |   (0.005)    |    (0.005)    |    (0.004)     |   (0.003)   |   (0.005)    |
|                         |              |              |               |                |             |              |
| Control Mean            |    0.787     |    0.671     |     0.457     |     0.217      |    0.121    |    0.668     |
| Num.Obs.                |    161146    |    161146    |    161146     |     161146     |   161146    |    161146    |
| R2                      |    0.155     |    0.207     |     0.173     |     0.141      |    0.145    |    0.175     |
| FE: school_id           |      X       |      X       |       X       |       X        |      X      |      X       |

: Impacts on Fall 2020 college enrollment outcomes {#tbl-20enroll}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement. Baseline covariates include fee waiver indicator, first-generation status, age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator, sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance. Robust standard errors clustered at the school level, reported in parentheses.

\newpage

|                         |  Fall 2020   |    4-year    | 4-year public | 4-year private |   2-year    |  Full-time   |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential | -0.021\*\*\* | -0.044\*\*\* |    -0.007     |  -0.037\*\*\*  | 0.022\*\*\* | -0.034\*\*\* |
|                         |   (0.005)    |   (0.006)    |    (0.007)    |    (0.006)     |   (0.004)   |   (0.006)    |
|                         |              |              |               |                |             |              |
| Control Mean            |    0.784     |    0.661     |     0.452     |     0.212      |    0.129    |    0.661     |
| Num.Obs.                |    97537     |    97537     |     97537     |     97537      |    97537    |    97537     |
| R2                      |    0.160     |    0.213     |     0.181     |     0.144      |    0.152    |    0.180     |
| FE: school_id           |      X       |      X       |       X       |       X        |      X      |      X       |

: Impacts on Fall 2020 college enrollment outcomes - Racially marginalized students {#tbl-20enrollurm}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement. Baseline covariates include fee waiver indicator, first-generation status, age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator, sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance. Robust standard errors clustered at the school level, reported in parentheses.

\newpage

|                         | Fall 2020 | Spring 2021 | Fall 2021 | Spring 2022 | Gap semester | Gap year |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential |  -0.017   |   -0.016    |  -0.011   |   -0.011    |    -0.001    |  0.006   |
|                         |  (0.010)  |   (0.011)   |  (0.011)  |   (0.011)   |   (0.004)    | (0.003)  |
|                         |           |             |           |             |              |          |
| Control Mean            |   0.787   |    0.724    |   0.701   |    0.651    |    0.025     |  0.022   |
| Num.Obs.                |   20527   |    20527    |   20527   |    20527    |    20527     |  20527   |
| R2                      |   0.282   |    0.295    |   0.303   |    0.315    |    0.212     |  0.222   |
| FE: school_id           |     X     |      X      |     X     |      X      |      X       |    X     |

: Impacts on college enrollment outcomes - Opt out {#tbl-20enrollopt}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: Opt-out was constructed by flagging students who explicitly messaged "STOP" to the bot at any point during the intervention and/or received a "goodbye" message from Oli, indicating that they had requested to opt out. Due to data quality issues we only have text message data for 70% of all treated students. Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement.Baseline covariates include fee waiver indicator, first-generation status,age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator,sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance.The gap semester outcome is a binary indicator coded as 1 if a student did not enroll in Fall 2020 but did enroll in Spring 2021. The gap year outcome is also a binary indicator coded as 1 if a student did not enroll in Fall 2020 or Spring 2021, but did enroll in Fall 2022. Robust standard errors clustered at the school level, reported in parentheses.

\newpage

|                         | Fall 2020 | 4-year  | 4-year public | 4-year private |   2-year    | Full-time |
|:----------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Enrollment Differential | 0.026\*\* |  0.002  |   0.032\*\*   |  -0.032\*\*\*  | 0.024\*\*\* |   0.005   |
|                         |  (0.009)  | (0.010) |    (0.011)    |    (0.009)     |   (0.007)   |  (0.010)  |
|                         |           |         |               |                |             |           |
| Control Mean            |   0.793   |  0.674  |     0.461     |     0.215      |    0.123    |   0.676   |
| Num.Obs.                |   26281   |  26281  |     26281     |     26281      |    26281    |   26281   |
| R2                      |   0.256   |  0.304  |     0.279     |     0.253      |    0.251    |   0.272   |
| FE: school_id           |     X     |    X    |       X       |       X        |      X      |     X     |

: Impacts of text message engagement on Fall 2020 college enrollment - High text engagement {#tbl-20enrolleng}

\**p* \< 0.05, \*\* *p* \< 0.01, \*\*\* *p* \< 0.001 Notes: High engagement indicator is coded as 1 for students who are in the top 25th percentile (sent more than 9 text messages) of total number of text messages students sent throughout the intervention. Due to data quality issues we only have text message data for 70% of all treated students. Analyses include school-level fixed effects and sampling weights to account for our propensity score matching approach with replacement.Baseline covariates include fee waiver indicator, first-generation status,age, gender, English spoken at home, dependent flag, attended more than one high school, high school GPA, SAT/ACT performance, college credit exams count, TOEFL indicator,sibling college indicator, submitted at least one CommonApp application before start of intervention, and race/ethnicity indicators. Additionally, we included indicators of missingness for high school GPA and SAT/ACT performance.Robust standard errors clustered at the school level, reported in parentheses.

\newpage

![Propensity score distribution](figures/ps_dist.png){#fig-psdist alt="Propensity score distribution" width="340"}
